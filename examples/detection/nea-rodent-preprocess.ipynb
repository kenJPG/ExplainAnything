{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xmltodict\n",
    "from dicttoxml import dicttoxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from pathlib import Path\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5\n",
    "\n",
    "def closest_pairs_hungarian(a, b):\n",
    "    \"\"\"Connect each body from list a to its closest tail from list b using the Hungarian algorithm.\"\"\"\n",
    "    num_bodies = len(a)\n",
    "    num_tails = len(b)\n",
    "    \n",
    "    # Create a matrix to store the distances between every body and tail\n",
    "    cost_matrix = np.zeros((num_bodies, num_tails))\n",
    "    \n",
    "    for i, body in enumerate(a):\n",
    "        for j, tail in enumerate(b):\n",
    "            cost_matrix[i][j] = euclidean_distance(body, tail)\n",
    "    \n",
    "    # Use the Hungarian algorithm to find the optimal assignment\n",
    "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Convert the result to a list of pairs\n",
    "    pairings = list(zip(row_indices, col_indices))\n",
    "    \n",
    "    return pairings\n",
    "\n",
    "def merge_bounding_boxes(box1, box2):\n",
    "    \"\"\"Merge two bounding boxes into one.\"\"\"\n",
    "    # Extract coordinates\n",
    "    x1a, y1a, x2a, y2a = box1\n",
    "    x1b, y1b, x2b, y2b = box2\n",
    "    \n",
    "    # New top-left coordinates will be the minimum of the x1 and y1 coordinates of both boxes\n",
    "    x1 = min(x1a, x1b)\n",
    "    y1 = min(y1a, y1b)\n",
    "    \n",
    "    # New bottom-right coordinates will be the maximum of the x2 and y2 coordinates of both boxes\n",
    "    x2 = max(x2a, x2b)\n",
    "    y2 = max(y2a, y2b)\n",
    "    \n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "def voc_to_yolo(voc_dict, class_mapping):\n",
    "    \"\"\"Convert Pascal VOC format dictionary to YOLO format strings.\"\"\"\n",
    "    yolo_data = []\n",
    "    \n",
    "    img_width = int(voc_dict['annotation']['size']['width'])\n",
    "    img_height = int(voc_dict['annotation']['size']['height'])\n",
    "\n",
    "    for obj in voc_dict['annotation']['object']:\n",
    "        # Extract coordinates from the VOC format\n",
    "        xmin = float(obj['bndbox']['xmin'])\n",
    "        ymin = float(obj['bndbox']['ymin'])\n",
    "        xmax = float(obj['bndbox']['xmax'])\n",
    "        ymax = float(obj['bndbox']['ymax'])\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        x_center = (xmin + xmax) / 2\n",
    "        y_center = (ymin + ymax) / 2\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        # Normalize the coordinates\n",
    "        x_center /= img_width\n",
    "        y_center /= img_height\n",
    "        width /= img_width\n",
    "        height /= img_height\n",
    "\n",
    "        class_id = class_mapping[obj['name']]\n",
    "        yolo_data.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    return yolo_data\n",
    "\n",
    "def merge_boxes(file_dir, filepath, save_dir):\n",
    "\tread_path = Path(file_dir) / filepath\n",
    "\txml_file = open(read_path,\"r\")\n",
    "\txml_string = xml_file.read()\n",
    "\tpython_dict = xmltodict.parse(xml_string)\n",
    "\n",
    "\ttails = []\n",
    "\tbodies = []\n",
    "\n",
    "\tif type(python_dict['annotation']['object']) == dict: \n",
    "\t\tpython_dict['annotation']['object'] = list([python_dict['annotation']['object']])\n",
    "\n",
    "\tfor obj_id, obj in enumerate(python_dict['annotation']['object']):\n",
    "\t\tcenter = [(int(obj['bndbox']['xmax']) + int(obj['bndbox']['xmin'])) / 2, (int(obj['bndbox']['ymax']) + int(obj['bndbox']['ymin'])) / 2]\n",
    "\t\tif obj['name'] == 'rat':\n",
    "\t\t\tbodies.append([obj_id, center])\n",
    "\t\telse:\n",
    "\t\t\ttails.append([obj_id, center])\n",
    "\n",
    "\t# Example\n",
    "\tbodies = np.array(bodies)\n",
    "\ttails = np.array(tails)\n",
    "\n",
    "\tused = []\n",
    "\tfinal = []\n",
    "\tif len(bodies) > 0 and len(tails) > 0:\n",
    "\t\tpairings = np.array(closest_pairs_hungarian(\n",
    "\t\t\tnp.stack(bodies[:, 1]),\n",
    "\t\t\tnp.stack(tails[:, 1])\n",
    "\t\t))\n",
    "\n",
    "\t\tfor i, (a, b) in enumerate(zip(np.stack(bodies[pairings[:, 0], 0]), np.stack(tails[pairings[:, 1], 0]))):\n",
    "\t\t\tused.append(a)\n",
    "\t\t\tused.append(b)\n",
    "\n",
    "\t\t\t# bodies[i]\n",
    "\n",
    "\t\t\ta_bbox = list(map(float, python_dict['annotation']['object'][a]['bndbox'].values()))\n",
    "\t\t\tb_bbox = list(map(float, python_dict['annotation']['object'][b]['bndbox'].values()))\n",
    "\n",
    "\t\t\tc_bbox = merge_bounding_boxes(a_bbox, b_bbox)\n",
    "\n",
    "\t\t\tfinal.append({\n",
    "\t\t\t\t'name': 'rat',\n",
    "\t\t\t\t'pose': 'Unspecified',\n",
    "\t\t\t\t'truncated': '0',\n",
    "\t\t\t\t'difficult': '0',\n",
    "\t\t\t\t'bndbox': {'xmin': c_bbox[0], 'ymin': c_bbox[1], 'xmax': c_bbox[2], 'ymax': c_bbox[3]}\n",
    "\t\t\t})\n",
    "\n",
    "\t\tused = list(sorted(used))[::-1]\n",
    "\n",
    "\tfor obj_id, obj in enumerate(python_dict['annotation']['object']):\n",
    "\t\tif len(used) > 0 and obj_id >= used[-1]:\n",
    "\t\t\tused.pop()\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tfinal.append({**obj, 'name': 'rat'})\n",
    "\tpython_dict['annotation']['object'] = final\n",
    "\n",
    "\tyolo_format = voc_to_yolo(python_dict, class_mapping = {'rat': 0})\n",
    "\t\n",
    "\twrite_file_name = python_dict['annotation']['filename'].rstrip('.jpg') + '.txt'\n",
    "\n",
    "\tmy_file = open(Path(save_dir) / write_file_name, 'w')\n",
    "\tmy_file.write(\"\\n\".join(yolo_format))\n",
    "\tmy_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6511/3574003477.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bodies = np.array(bodies)\n",
      "/tmp/ipykernel_6511/3574003477.py:97: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tails = np.array(tails)\n"
     ]
    }
   ],
   "source": [
    "for filepath in list(sorted(os.listdir('/app/data'))):\n",
    "\tif filepath[-3:] == 'xml':\n",
    "\t\tmerge_boxes('/app/data', filepath, '/app/rats/labels/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
