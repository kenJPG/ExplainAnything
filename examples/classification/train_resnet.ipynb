{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ResNet\n",
    "In this notebook we train a simple resnet50 to classify celebrity sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import warnings\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3622212"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile = open('data/original/CelebAMask-HQ/CelebAMask-HQ-attribute-anno.txt', 'r')\n",
    "\n",
    "mytext = myfile.readlines()[1:]\n",
    "csv_file = open('custom_dataset.csv', 'w')\n",
    "csv_file.write(\"\".join(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = list(sorted(['data/original/CelebAMask-HQ/CelebA-HQ-img/'+filename.split('_')[0] for filename in os.listdir('data/original/CelebAMask-HQ/CelebA-HQ-img/') if isfile(join('data/original/CelebAMask-HQ/CelebA-HQ-img/', filename))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('custom_dataset.csv', delimiter = ' ')\n",
    "dataset.index = list(map(lambda x: x[0], dataset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_prob_dist(labels: torch.tensor, size = 2):\n",
    "\tarr = np.full((len(labels), size), 0)\n",
    "\tfor i, label in enumerate(labels):\n",
    "\t\tarr[i][int(label.item())] = 1\n",
    "\treturn torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "class CelebDataset(Dataset):\n",
    "\tdef __init__(self, csv_file, root_dir, transform=None):\n",
    "\t\t\"\"\"\n",
    "\t\tArguments:\n",
    "\t\t\tcsv_file (string): Path to the csv file with annotations.\n",
    "\t\t\troot_dir (string): Directory with all the images.\n",
    "\t\t\ttransform (callable, optional): Optional transform to be applied\n",
    "\t\t\t\ton a sample.\n",
    "\t\t\"\"\"\n",
    "\t\tself.label_frame = pd.read_csv(csv_file, delimiter = ' ')\n",
    "\t\t# self.label_frame.index = list(map(lambda x: x[0], self.label_frame.index))\n",
    "\t\tself.labels = self.label_frame.loc[\n",
    "\t\t\tlist(map(lambda x: x.split('/')[-1],\n",
    "\t\t\t\t\t all_imgs\n",
    "\t\t\t\t\t))\n",
    "\t\t]['Male']\n",
    "\n",
    "\t\tself.labels = torch.tensor((self.labels.values == 1).astype(np.uint8))\n",
    "\t\tself.imgs = list(map(lambda x: x[0],\n",
    "\t\t\tself.label_frame.loc[list(sorted(map(lambda x: x.split('/')[-1],all_imgs)))].index.values\n",
    "\t\t\t\t\t\t\t))\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.label_frame)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tif torch.is_tensor(idx):\n",
    "\t\t\tidx = idx.tolist()\n",
    "\n",
    "\t\timg_name = os.path.join(self.root_dir,\n",
    "\t\t\t\t\t\t\t\tself.imgs[idx])\n",
    "\t\t\n",
    "\t\timage = Image.open(img_name)\n",
    "\t\tlabel = torch.tensor([self.labels[idx]])\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image)\n",
    "\n",
    "\t\treturn image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_dataset = CelebDataset(\n",
    "    csv_file = 'custom_dataset.csv',\n",
    "    root_dir = 'data/original/CelebAMask-HQ/CelebA-HQ-img',\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                          std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(celeb_dataset, [20000, 5000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def accurate_count(pred, true):\n",
    "    return (torch.round(pred).int() == true).sum()\n",
    "\n",
    "class CustomEarlyStopping():\n",
    "\tdef __init__(self, patience, min_loss_delta = 0, min_acc_delta = 0):\n",
    "\t\tself.patience = patience\n",
    "\t\tself.best_loss = 1e9\n",
    "\t\tself.best_acc = 0\n",
    "\t\tself.patience_count = 0\n",
    "\t\tself.count = 0\n",
    "\t\tself.stop = False\n",
    "\n",
    "\t\tself.min_loss_delta = min_loss_delta\n",
    "\t\tself.min_acc_delta = min_acc_delta\n",
    "\n",
    "\tdef __call__(self, loss, accuracy):\n",
    "\t\tself.save_state = False\n",
    "\n",
    "\t\tif self.best_loss - loss > self.min_loss_delta or accuracy - self.best_acc > self.min_acc_delta:\n",
    "\t\t\tif self.best_loss - loss > self.min_loss_delta:\n",
    "\t\t\t\tself.best_loss = loss\n",
    "\t\t\tif accuracy - self.best_acc > self.min_acc_delta:\n",
    "\t\t\t\tself.best_acc = accuracy\n",
    "\n",
    "\t\t\tself.count = 0\n",
    "\t\telse:\n",
    "\t\t\tself.count += 1\n",
    "\t\t\n",
    "\t\tif self.count >= self.patience:\n",
    "\t\t\tself.stop = True\n",
    "            \n",
    "def train_model(model_name, model, n_epochs, optimizer, criterion, batch_size, early_stopping, train_set, val_set, device):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 4)\n",
    "    val_loader = DataLoader(val_set, batch_size = batch_size, num_workers = 4)\n",
    "\n",
    "    best_val_loss = 1e9\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        train_acc_count = 0\n",
    "        total_sample = 0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc_count += accurate_count(outputs, labels)\n",
    "            total_sample += len(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc_count / total_sample\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_acc_count = 0\n",
    "        total_sample = 0\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_acc_count += accurate_count(outputs, labels)\n",
    "                total_sample += len(labels)\n",
    "\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        val_acc = val_acc_count / total_sample\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.5f} \\tVal Loss: {val_loss:.5f} \\tTrain Acc: {train_acc:.3f} \\tVal Acc: {val_acc:.3f}\")\n",
    "\n",
    "        done = epoch\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "            with open(f'{model_name}_best_loss_checkpoint.pkl', 'wb') as myfile:\n",
    "                torch.save(model.state_dict(), myfile)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            with open(f'{model_name}_best_acc_checkpoint.pkl', 'wb') as myfile:\n",
    "                torch.save(model.state_dict(), myfile)\n",
    "\n",
    "        early_stopping(val_loss, val_acc)\n",
    "\n",
    "        if early_stopping.stop:\n",
    "            print(\"Stopping due to early stopping | patience =\", early_stopping.patience)\n",
    "            \n",
    "def eval_model(model, test_set, batch_size, device):\n",
    "    test_loader = DataLoader(test_set, batch_size = batch_size, num_workers = 4)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_sample = 0\n",
    "    test_acc_count = 0\n",
    "\n",
    "    output = []\n",
    "    input_list = []\n",
    "    label = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            input_list.append(inputs.detach().cpu().numpy())    \n",
    "            label.append(labels.detach().cpu().numpy())\n",
    "            output.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "            test_acc_count += accurate_count(outputs, labels)\n",
    "\n",
    "            total_sample += len(labels)\n",
    "    \n",
    "    output = np.concatenate(output).flatten()\n",
    "    output = np.round(output).astype(int)\n",
    "    label = np.concatenate(label).flatten().astype(int)\n",
    "    \n",
    "    print(output.shape, label.shape)\n",
    "    \n",
    "    print(classification_report(\n",
    "        y_true = label,\n",
    "        y_pred = output,\n",
    "        target_names = ['Female', 'Male']\n",
    "    ))\n",
    "            \n",
    "    test_acc = test_acc_count / total_sample\n",
    "    \n",
    "    return test_acc\n",
    "            \n",
    "import math\n",
    "\n",
    "def imshow(arr: list, label: list = None, figsize=None, shape = (32, 32, 3), is_int = None):\n",
    "\tif is_int == None:\n",
    "\t\tif type(arr[0]) == torch.Tensor:\n",
    "\t\t\tis_int = (arr[0].detach().cpu().numpy() > 1).sum() > 0\n",
    "\t\telse:\n",
    "\t\t\tis_int = (arr[0] > 1).sum() > 0\n",
    "\tif label == None:\n",
    "\t\tlabel = [''] * len(arr)\n",
    "\n",
    "\theight = int(len(arr) ** 0.5)\n",
    "\twidth = math.ceil(len(arr) / height)\n",
    "\n",
    "\tif figsize == None:\n",
    "\t\tfig = plt.figure()\n",
    "\telse:\n",
    "\t\tfig = plt.figure(figsize=figsize)\n",
    "\tfor i in range(height):\n",
    "\t\tfor j in range(width):\n",
    "\t\t\tax = fig.add_subplot(height, width, i * height + j + 1)\n",
    "\t\t\tax.grid(False)\n",
    "\t\t\tax.set_xticks([])\n",
    "\t\t\tax.set_yticks([])\n",
    "\t\t\tshow = arr[i * height + j]\n",
    "\t\t\tif type(arr[i * height + j]) != torch.Tensor:\n",
    "\t\t\t\tshow = torch.Tensor(show)\n",
    "\t\t\tif len(show.squeeze(0).cpu().shape) == 2:\n",
    "\t\t\t\tax.imshow((show.squeeze(0).detach().cpu()).type(torch.uint8 if is_int else torch.float), cmap='gray')\n",
    "\t\t\telse:\n",
    "\t\t\t\tax.imshow((show.squeeze(0).detach().cpu().permute(1,2,0)).type(torch.uint8 if is_int else torch.float))\n",
    "\t\t\tax.set_title(label[i * height + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "model = resnet50(weights = None)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features = 2048, out_features = 1, bias = True),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.33473 \tVal Loss: 0.18429 \tTrain Acc: 0.850 \tVal Acc: 0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.11841 \tVal Loss: 0.15126 \tTrain Acc: 0.953 \tVal Acc: 0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.09742 \tVal Loss: 0.10521 \tTrain Acc: 0.964 \tVal Acc: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:47<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.07352 \tVal Loss: 0.12550 \tTrain Acc: 0.972 \tVal Acc: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.05879 \tVal Loss: 0.09999 \tTrain Acc: 0.979 \tVal Acc: 0.966\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model_name = 'RN50',\n",
    "    model = model,\n",
    "    n_epochs = 5,\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3),\n",
    "    criterion = torch.nn.BCELoss(),\n",
    "    batch_size = 128,\n",
    "    early_stopping = CustomEarlyStopping(patience = 5),\n",
    "    train_set = train_set,\n",
    "    val_set = val_set, \n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights = None)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features = 2048, out_features = 1, bias = True),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "model.load_state_dict(torch.load('RN50_best_acc_checkpoint.pkl'))\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,) (5000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.98      0.97      0.97      3146\n",
      "        Male       0.95      0.96      0.95      1854\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.96      0.97      0.96      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9660, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_set, 128, device = \"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:09<00:00, 11.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "model = resnet50(weights = ResNet50_Weights.DEFAULT)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features = 2048, out_features = 1, bias = True),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.07698 \tVal Loss: 0.07818 \tTrain Acc: 0.972 \tVal Acc: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.03939 \tVal Loss: 0.16602 \tTrain Acc: 0.985 \tVal Acc: 0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:47<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.02559 \tVal Loss: 0.07209 \tTrain Acc: 0.991 \tVal Acc: 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:47<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.02230 \tVal Loss: 0.18221 \tTrain Acc: 0.991 \tVal Acc: 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:46<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.01613 \tVal Loss: 0.07577 \tTrain Acc: 0.995 \tVal Acc: 0.975\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model_name = 'RN50_pretrained',\n",
    "    model = model,\n",
    "    n_epochs = 5,\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3),\n",
    "    criterion = torch.nn.BCELoss(),\n",
    "    batch_size = 128,\n",
    "    early_stopping = CustomEarlyStopping(patience = 5),\n",
    "    train_set = train_set,\n",
    "    val_set = val_set, \n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights = None)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features = 2048, out_features = 1, bias = True),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "model.load_state_dict(torch.load('RN50_pretrained_best_acc_checkpoint.pkl'))\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,) (5000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.96      1.00      0.98      3141\n",
      "        Male       1.00      0.94      0.97      1859\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.98      0.97      0.97      5000\n",
      "weighted avg       0.98      0.98      0.98      5000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9760, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_set, 128, device = \"cuda:0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
